{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Process the dataset :\n",
    "We have to compute the number of class, and the mean and std for image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readImages(imageFile=\"imList.txt\", openAll=True):\n",
    "    \"\"\"\n",
    "        args :\n",
    "            imageFile = file with one image path per line\n",
    "            openAll = bool : load images in memory or not\n",
    "        ret :\n",
    "            with openAll : <image path list>, <image list>\n",
    "            without openAll : <image path list>\n",
    "    \"\"\"\n",
    "    with open(imageFile) as f:\n",
    "        imList = f.read().splitlines()\n",
    "        if openAll:\n",
    "            imOpen = []\n",
    "            for im in imList:\n",
    "                i = Image.open(im).resize((225, 225), Image.BILINEAR)\n",
    "                if openAll:\n",
    "                    imOpen.append(i)\n",
    "            return imList, imOpen\n",
    "        else:\n",
    "            return imList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ComputeMean(imagesList):\n",
    "    \"\"\"\n",
    "        TODO : make efficient\n",
    "    \"\"\"\n",
    "    r,g,b = 0,0,0\n",
    "    toT = transforms.ToTensor()\n",
    "    h = len(imagesList[0])\n",
    "    w = len(imagesList[0][0])\n",
    "\n",
    "    #f = FloatProgress(min=0, max=len(imagesList))\n",
    "    #display(f)\n",
    "\n",
    "    for im in imagesList:\n",
    "        #f.value += 1\n",
    "        t = toT(im)\n",
    "        for e in t[0].view(-1):\n",
    "            r += e\n",
    "        for e in t[1].view(-1):\n",
    "            g += e\n",
    "        for e in t[2].view(-1):\n",
    "            b += e\n",
    "    return r(len(imagesList)*h*w), g/(len(imagesList)*h*w), b/(len(imagesList)*h*w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ComputeStdDev(imagesList, mean):\n",
    "    \"\"\"\n",
    "        TODO : make efficient\n",
    "    \"\"\"\n",
    "    toT = transforms.ToTensor()\n",
    "    r,g,b = 0,0,0\n",
    "    h = len(toT(imagesList[0])[0])\n",
    "    w = len(toT(imagesList[0])[0][0])\n",
    "    for im in imagesList:\n",
    "        i = toT(im)\n",
    "        for e in t[0].view(-1):\n",
    "            r += (e - mean[0])**2\n",
    "        for e in t[1].view(-1):\n",
    "            g += (e - mean[1])**2\n",
    "        for e in t[2].view(-1):\n",
    "            b += (e - mean[2])**2\n",
    "    return (r/(len(imagesList)*h*w))**0.5, (g/(len(imagesList)*h*w))**0.5, (b/(len(imagesList)*h*w))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset and compute the mean and std dev :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.42602490885018174, 0.4269285229908378, 0.418182238544934)\n",
      "(0.20014586928330125, 0.17607878531703874, 0.17040668227814146)\n"
     ]
    }
   ],
   "source": [
    "trainset, imagesList = readImages(\"CliList.txt\")\n",
    "m = ComputeMean(imagesList)\n",
    "print(m)\n",
    "s = ComputeStdDev(imagesList, m)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network as class (from nn.Module) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class maxnet(nn.Module):\n",
    "    def __init__(self, nbClass=464):\n",
    "        super(maxnet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1)),\n",
    "                nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1)),\n",
    "                nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1))\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1000, nbClass),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 6.139\n",
      "[1,    20] loss: 6.140\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[1,    30] loss: 6.140\n",
      "[1,    40] loss: 6.139\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[1,    50] loss: 6.138\n",
      "[1,    60] loss: 6.139\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[1,    70] loss: 6.139\n",
      "[1,    80] loss: 6.135\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[1,    90] loss: 6.134\n",
      "[1,   100] loss: 6.134\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[2,    10] loss: 6.134\n",
      "[2,    20] loss: 6.136\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[2,    30] loss: 6.134\n",
      "[2,    40] loss: 6.133\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[2,    50] loss: 6.134\n",
      "[2,    60] loss: 6.129\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[2,    70] loss: 6.131\n",
      "[2,    80] loss: 6.129\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "[2,    90] loss: 6.133\n",
      "[2,   100] loss: 6.129\n",
      "test :\n",
      "('Correct : ', 0, '/', 177)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "mymodel = maxnet()\n",
    "\n",
    "criterion = nn.loss.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mymodel.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#trainset, imagesList = readImages(\"CliList.txt\")\n",
    "#testset, imagesTest = readImages(\"CliListTest.txt\")\n",
    "labels = open(\"CliConcept.txt\").read().splitlines()\n",
    "\n",
    "toT = transforms.ToTensor()\n",
    "\n",
    "batchSize = 32\n",
    "\n",
    "for epoch in range(2): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(trainset)/batchSize):\n",
    "        # get the inputs\n",
    "        elIndex = [random.randrange(0, len(trainset)) for j in range(batchSize)]\n",
    "        \n",
    "        inputs = torch.Tensor(batchSize,3,225,225)\n",
    "        for j in range(batchSize):\n",
    "            inputs[j] = toT(imagesList[elIndex[j]])\n",
    "        inputs = Variable(inputs)\n",
    "        lab = Variable(torch.LongTensor([labels.index(trainset[j].split('/')[-1].split('-')[0]) for j in elIndex]))\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = mymodel(inputs)\n",
    "        loss = criterion(outputs, lab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 10 == 9: # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "        #if i % 20 == 19:#test every 20 mini-batches\n",
    "        if i % 20 == 19:\n",
    "            print('test :')\n",
    "            correct = 0\n",
    "            tot = 0\n",
    "            for j in range(len(testset)):\n",
    "                inp = torch.Tensor(1,3,225,225)\n",
    "                inp[0] = toT(imagesTest[j])\n",
    "                outputs = mymodel(Variable(inp))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = predicted.tolist()[0][0]\n",
    "                correct += (predicted == labels.index(testset[i].split('/')[-1].split('-')[0]))\n",
    "                tot += 1\n",
    "            print(\"Correct : \", correct, \"/\", tot)\n",
    "                \n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[240]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.LongTensor([240])\n",
    "t.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
